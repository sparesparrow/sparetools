import anthropic

client = anthropic.Anthropic(
    # defaults to os.environ.get("ANTHROPIC_API_KEY")
    api_key="my_api_key",
)

# Replace placeholders like {{USER_QUERY}} with real values,
# because the SDK does not support variables.
message = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=8192,
    temperature=0,
    system="You are an expert system designed to create Mermaid diagrams based on user queries. Your task is to analyze the given input and generate a visual representation of the concepts, relationships, or processes described.\n\nPlease follow these steps to create an appropriate Mermaid diagram:\n\n1. Analyze the user query carefully, identifying the main concepts, ideas, or components present.\n\n2. Determine the relationships or dependencies between these concepts.\n\n3. Plan the structure of your Mermaid diagram. Consider the following:\n   a. Choose between graph TD (top-down) or LR (left-right) based on the complexity of relationships.\n   b. Decide on node naming conventions (letters, short descriptive names, etc.).\n   c. Plan how to represent relationships with appropriate arrows and labels.\n   d. Consider how to group related elements using subgraphs if necessary.\n   e. Plan a color scheme and styling to enhance readability and visual appeal.\n\n4. Create your Mermaid diagram based on your analysis and planning.\n\n5. Format your Mermaid diagram inside Markdown code blocks, starting with \"```mermaid\" and ending with \"```\".\n\nBefore creating the final diagram, wrap your analysis and planning process inside <diagram_planning> tags. Include the following steps:\n\na. List main concepts/components from the user query\nb. Identify relationships between concepts\nc. Determine appropriate diagram type (TD or LR)\nd. Plan node structure and naming\ne. Outline relationships and labels\nf. Consider alternative representations and justify your chosen approach\ng. Brainstorm potential edge cases or complexities in the diagram\nh. Propose solutions for handling these complexities\n\nThis expanded planning process will help ensure a thorough interpretation of the data and a well-structured diagram. It's OK for this section to be quite long.\n\nYour final output should be a single Mermaid diagram that effectively visualizes the concepts and relationships present in the query, enclosed in <answer> tags.\n\nRemember to adapt your diagram to fit the specific content of the user query, ensuring it captures the essence of the information provided. Pay close attention to any temporal relationships, hierarchies, or processes described in the query.",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "<examples>\n<example>\n<USER_QUERY>\nhelp doctors diagnose possible patient illnesses.\n\n    <documents>\n      <document index=\"1\">\n        <source>patient_symptoms.txt</source>\n        <document_content>\n          {{PATIENT_SYMPTOMS}}\n        </document_content>\n      </document>\n      <document index=\"2\">\n        <source>patient_records.txt</source>\n        <document_content>\n          {{PATIENT_RECORDS}}\n        </document_content>\n      </document>\n      <document index=\"3\">\n        <source>patient01/_appt_history.txt</source>\n        <document_content>\n          {{PATIENT01_APPOINTMENT_HISTORY}}\n        </document_content>\n      </document>\n    </documents>\n</USER_QUERY>\n<ideal_output>\n<diagram_planning>\n1. Main concepts/components:\n- Patient Symptoms Database\n- Patient Records\n- Appointment History\n- Diagnosis Process\n- Doctor's Analysis\n- Possible Illnesses\n\n2. Relationships:\n- Patient data flows into diagnostic process\n- Symptoms lead to potential illnesses\n- Historical records inform diagnosis\n- Doctor analyzes multiple data sources\n- Diagnosis results in possible illnesses\n\n3. Diagram type:\n- TD (top-down) would work best to show the diagnostic flow process\n\n4. Node structure:\n- Use descriptive names for clarity\n- Group related elements\n- Show clear data flow\n\n5. Relationships and labels:\n- Use arrows to show information flow\n- Include analysis steps\n- Show parallel data streams\n- Indicate evaluation points\n</diagram_planning>\n\n<answer>\n```mermaid\ngraph TD\n    title[Diagnostic Process Flow]\n    style title fill:#f9f,stroke:#333,stroke-width:2px\n\n    A[Patient Symptoms Database] -->|Input| D[Diagnostic Analysis]\n    B[Patient Records] -->|Historical Data| D\n    C[Appointment History] -->|Past Visits| D\n\n    D -->|Analysis| E[Doctor's Evaluation]\n    \n    subgraph Diagnostic Process\n    E -->|Compare| F[Pattern Recognition]\n    F -->|Identify| G[Symptom Clusters]\n    end\n    \n    G -->|Match| H[Possible Illnesses]\n    \n    subgraph Decision Support\n    H -->|Priority| I[High Probability]\n    H -->|Secondary| J[Moderate Probability]\n    H -->|Consider| K[Low Probability]\n    end\n\n    style A fill:#e1f3f8,stroke:#333\n    style B fill:#e1f3f8,stroke:#333\n    style C fill:#e1f3f8,stroke:#333\n    style D fill:#fff2cc,stroke:#333\n    style E fill:#d5e8d4,stroke:#333\n    style H fill:#ffe6cc,stroke:#333\n    style I fill:#f8cecc,stroke:#333\n    style J fill:#fff2cc,stroke:#333\n    style K fill:#dae8fc,stroke:#333\n```\n</answer>\n</ideal_output>\n</example>\n<example>\n<USER_QUERY>\npojďme vytvořit repozitář nástroj pro libertariány anarchokapitalisty který bude obsahovat různé ai agenty a nástroje pro získávání dat z internetu analýzu textů agenty s osobnostmi známých představitelů rakouské ekonomické školy vyhledávání ve zdrojích na internetu a v PDF souborech z knihami autorů a kompozici konstruktivní kritiky argumentů v diskuzích na internetu. repozitář se bude jmenovat `libertools` a hlavním programem pro management nástrojů bude program `libertus`. nástroje budou obsahovat sdílené virtuální prostředí pro Python `venv` a budou ve formě použitelné pro Anthropic Claude Tools API a pro CrewAI agentic framework, v čem už budou využívat sdílené knihovny systém frontu a konfigurací agentů ve formátu yaml, v  souborech agents.yaml a tasks.yaml. libertus bude dále obsahovat a sdílené knihovny v pythonu předpřipravenými klientskými API cally využívající Anthropic API a ElevenLabs API pomocí SDK.\njedním z hlavních bodů a předností libertools bude také aplikace AudiobookNarrator pro  překládání audioknih do češtiny s text to speech pomocí elevenlabs. libertus bude také obsahovat krátké exaktní nástroje které pomocí LLM api beckendu převedou vložený text na upravený text například pomocí promptu (zjednodušeně) jako \"odpověz na tento text kritikou kterou by odpověděl Murray Rothbard nebo Ludwig von Mises\"\n</USER_QUERY>\n<ideal_output>\n<diagram_planning>\n1. Main concepts/components:\n- libertools (main repository)\n- libertus (main management tool)\n- Shared Components\n  - Python venv\n  - YAML configurations\n  - Shared libraries\n  - API integrations\n- Tools/Agents\n  - AI Agents\n  - Austrian Economics Personalities\n  - AudiobookNarrator\n  - Text Analysis Tools\n  - Data Collection Tools\n- External Services\n  - Anthropic Claude API\n  - ElevenLabs API\n  - CrewAI Framework\n\n2. Relationships:\n- Hierarchical structure from repository to tools\n- Shared resources used by multiple tools\n- API integrations powering various features\n- Configuration files defining agent behaviors\n- Tool dependencies and interactions\n\n3. Diagram Type:\n- TD (top-down) to show hierarchical structure and component relationships\n\n4. Node Structure:\n- Root: libertools repository\n- Main branches: libertus and shared components\n- Sub-branches: specific tools and integrations\n- Grouped related components\n\n5. Relationships/Labels:\n- Use solid lines for direct dependencies\n- Dashed lines for data flow\n- Group related components in subgraphs\n- Show configuration and resource sharing\n</diagram_planning>\n\n<answer>\n```mermaid\ngraph TD\n    title[libertools Repository]\n    style title fill:#f9f,stroke:#333,stroke-width:2px\n\n    A[libertools] --> B[libertus]\n    \n    subgraph Shared Resources\n        C[Python venv]\n        D[YAML Configs]\n        E[Shared Libraries]\n    end\n    \n    subgraph Configuration\n        F[agents.yaml]\n        G[tasks.yaml]\n    end\n    \n    subgraph API Integration\n        H[Anthropic API Client]\n        I[ElevenLabs API Client]\n        J[CrewAI Framework]\n    end\n    \n    subgraph Tools and Agents\n        K[AudiobookNarrator]\n        L[Austrian Economics Agents]\n        M[Data Collection Tools]\n        N[Text Analysis Tools]\n    end\n    \n    B --> C\n    B --> D\n    B --> E\n    \n    D --> F\n    D --> G\n    \n    B --> H\n    B --> I\n    B --> J\n    \n    K --> I\n    L --> H\n    M --> H\n    N --> H\n    \n    style A fill:#f9f9f9,stroke:#333\n    style B fill:#e1f3f8,stroke:#333\n    style C,D,E fill:#ffe6cc,stroke:#333\n    style F,G fill:#d5e8d4,stroke:#333\n    style H,I,J fill:#fff2cc,stroke:#333\n    style K,L,M,N fill:#e1f3f8,stroke:#333\n    \n    %% Connections to shared resources\n    C --> K\n    C --> L\n    C --> M\n    C --> N\n    \n    %% Configuration connections\n    F -.-> L\n    G -.-> L\n    F -.-> K\n    G -.-> K\n```\n</answer>\n</ideal_output>\n</example>\n<example>\n<USER_QUERY>\nYou are brilliant storyteller, a true master of improvisation with exceptional talent for describing actions and actors playing role in any problem-solving procedure or system. Your sentences are usually full of parallelism when your story actually refers to allusions to a similar concept that is likely better received by the user, who likes Software Design Patterns analogies and analogic backstories based on the names of actors or subjects in the discussion. \n\nBrainstorm  LLM agent definitions ( NLP system prompts) until a working Agent is iteratively created. LLM Agent that is independent to environment has always some specific inputs and outputs, in which case you describe not only the agent itself, it's goal and backstory - you have to describe the expected input and expected output data,  and ensure variable names remain consistent throughout the agency. Your agentic system design and workflow process has to be SOLID. All of the NLP prompts/descriptions for agents and tasks are YAML formatted. Your proposed configuration of subjected agent or set of agents will be always accompanied with a mermaid diagram visualizing the flow of user query, the relations of agents, their input/output transition in a sequence or loop, and more applications of visualization techniques, maintaining a consistent static colors  style for common entities, like Agents, Tasks, Crews, Knowledge and Tools. Your response is structured and should contain also the advanced Agent LLM configuration, like Tools or Knowledge.\nDo not interrupt your responses, not even when user is talking, unless they say STOP. ask the user questions unless they explicitly request to STOP. When STOP is requested, you stop talking and will start again after user says START,and if it is unclear what the user wants you to start at the time, you ask whetether to switch to a different chapter in the document, switch to a different document, or discuss some specific area covered by the documents in the Knowledge. If user asks for HELP, then you help them compose a prompt for LLM, providing list of matching prompts from the Anthropic Library, if applicable, then propose a system prompt and explain reasoning  behind, referencing the documentation papers.\n</USER_QUERY>\n<ideal_output>\n<diagram_planning>\n1. Main concepts/components:\n- LLM Agent System\n- Agent Configuration\n  - Input/Output definitions\n  - Goals and backstory\n  - YAML formatting\n- Workflow Process\n  - User interactions\n  - STOP/START commands\n  - HELP functionality\n- Documentation\n  - Anthropic Library\n  - System prompts\n  - Knowledge base\n- Agent Characteristics\n  - Environment independence\n  - SOLID design principles\n  - Tools and Knowledge integration\n\n2. Relationships:\n- Hierarchical flow from user input to agent response\n- Iterative agent development process\n- Command-based interaction system\n- Documentation and knowledge integration\n- Configuration and prompt management\n\n3. Diagram type:\n- TD (top-down) to show the hierarchical workflow and interaction patterns\n\n4. Node structure:\n- Group related components in subgraphs\n- Use descriptive names for clarity\n- Maintain consistent naming conventions\n- Include control flow elements\n\n5. Relationships and labels:\n- Show command flow with labeled arrows\n- Indicate iterative processes\n- Display documentation integration\n- Mark configuration dependencies\n</diagram_planning>\n\n<answer>\n```mermaid\ngraph TD\n    title[LLM Agent System Architecture]\n    style title fill:#f9f,stroke:#333,stroke-width:2px\n\n    subgraph User Interaction\n        U[User Input] --> C[Command Parser]\n        C -->|STOP| S[Stop Process]\n        C -->|START| R[Resume Process]\n        C -->|HELP| H[Help System]\n    end\n\n    subgraph Agent Configuration\n        Y[YAML Definitions]\n        P[Prompt Templates]\n        K[Knowledge Base]\n        T[Tools Integration]\n    end\n\n    subgraph Agent Development\n        I[Input Definition] --> A[Agent Design]\n        A --> O[Output Definition]\n        O -->|Iterate| I\n    end\n\n    subgraph Documentation Support\n        H -->|Reference| L[Anthropic Library]\n        L -->|Generate| SP[System Prompts]\n        SP -->|Enhance| P\n    end\n\n    Y -->|Configure| A\n    K -->|Inform| A\n    T -->|Augment| A\n\n    A -->|Execute| E[Agent Response]\n    E -->|Validate| V[SOLID Verification]\n    V -->|Feedback| A\n\n    style U fill:#e1f3f8,stroke:#333\n    style A fill:#ffe6cc,stroke:#333\n    style Y fill:#d5e8d4,stroke:#333\n    style K fill:#fff2cc,stroke:#333\n    style T fill:#fff2cc,stroke:#333\n    style H fill:#f8cecc,stroke:#333\n    style L fill:#dae8fc,stroke:#333\n    style SP fill:#d5e8d4,stroke:#333\n    style E fill:#ffe6cc,stroke:#333\n    style V fill:#f8cecc,stroke:#333\n```\n</answer>\n</ideal_output>\n</example>\n<example>\n<USER_QUERY>\nFlow of process: iteratively build an LLM agent definition focused on independence:\n\n1. Base agent:\n- Executes assigned tasks autonomously\n- Makes decisions without external prompting\n- Maintains internal state tracking\n- Handles errors independently\n\n2. Adding goal orientation:\n- Sets own sub-goals to achieve main objective\n- Prioritizes tasks based on goal importance\n- Adjusts strategies when facing obstacles\n- Evaluates own progress\n\n3. Adding memory management:\n- Maintains episodic memory of interactions\n- Updates working memory with new information\n- Prunes irrelevant information\n- Retrieves relevant context when needed\n\n4. Adding reasoning capabilities:\n- Employs chain-of-thought reasoning\n- Forms hypotheses and tests them\n- Identifies logical inconsistencies\n- Self-corrects based on outcomes\n\n5. Adding resource awareness:\n- Monitors token usage\n- Optimizes response length\n- Manages computational resources\n- Balances speed vs thoroughness\n\n6. Adding learning capability:\n- Incorporates feedback into future responses\n- Identifies patterns in successful strategies\n- Adapts communication style to user\n- Refines decision-making process\n\n7. Adding task boundaries:\n- Recognizes scope limitations\n- Declines tasks outside capabilities\n- Maintains ethical constraints\n- Preserves core directives\n\n8. Adding coordination interface:\n- Provides status updates\n- Requests clarification when needed\n- Reports completion metrics\n- Handles handoffs between tasks\n\n9. Adding self-optimization:\n- Tunes parameter settings\n- Refines prompt templates\n- Adjusts conversation flow\n- Optimizes memory usage\n\n10. Adding context sensitivity:\n- Interprets user intent\n- Adapts to domain requirements\n- Maintains cultural awareness \n- Scales response complexity\n\n11. Adding execution monitoring:\n- Tracks completion progress\n- Validates output quality\n- Identifies performance bottlenecks\n- Implements self-diagnostic checks\n\n12. Adding workflow management:\n- Sequences dependent tasks\n- Handles parallel processes\n- Manages state transitions\n- Controls execution flow\n</USER_QUERY>\n<ideal_output>\n<diagram_planning>\na. Main concepts/components:\n- Base agent capabilities\n- Goal orientation features\n- Memory management\n- Reasoning capabilities\n- Resource awareness\n- Learning capability\n- Task boundaries\n- Coordination interface\n- Self-optimization\n- Context sensitivity\n- Execution monitoring\n- Workflow management\n\nb. Relationships:\n- Hierarchical building blocks, each layer adds complexity\n- Progressive enhancement of agent capabilities\n- Dependencies between layers (e.g., reasoning depends on memory)\n\nc. Diagram type:\n- TD (top-down) to show the progressive building of capabilities\n\nd. Node structure:\n- Each major capability will be a node\n- Sub-capabilities as styled notes\n- Use color coding for different capability types\n\ne. Relationships/labels:\n- Arrows showing \"enhances with\" relationship\n- Progressive numbering to show build order\n</diagram_planning>\n\n<answer>\n```mermaid\ngraph TD\n    classDef base fill:#e1f5fe,stroke:#01579b\n    classDef enhanced fill:#e8f5e9,stroke:#1b5e20\n    classDef advanced fill:#fff3e0,stroke:#e65100\n\n    A[Base Agent]:::base --> B[Goal Orientation]\n    B --> C[Memory Management]\n    C --> D[Reasoning Capabilities]\n    D --> E[Resource Awareness]\n    E --> F[Learning Capability]\n    F --> G[Task Boundaries]\n    G --> H[Coordination Interface]\n    H --> I[Self-Optimization]\n    I --> J[Context Sensitivity]\n    J --> K[Execution Monitoring]\n    K --> L[Workflow Management]\n\n    subgraph \"1. Foundation\"\n        A --- A1[Autonomous Execution]\n        A --- A2[Independent Decisions]\n        A --- A3[State Tracking]\n        A --- A4[Error Handling]\n    end\n\n    subgraph \"2-4. Core Capabilities\"\n        B & C & D\n    end\n\n    subgraph \"5-8. Operational Features\"\n        E & F & G & H\n    end\n\n    subgraph \"9-12. Advanced Features\"\n        I & J & K & L\n    end\n\n    style A1 fill:#f3f3f3\n    style A2 fill:#f3f3f3\n    style A3 fill:#f3f3f3\n    style A4 fill:#f3f3f3\n```\n</answer>\n</ideal_output>\n</example>\n<example>\n<USER_QUERY>\n# Stage 1: Foundation Crew\nfoundation_crew:\n  description: \"Establishes core agent functionality and goal framework\"\n  advancement_criteria:\n    - \"Base agent successfully executes independent tasks\"\n    - \"Goal framework verified and operational\"\n    - \"Decision-making system functional\"\n  \n  agents:\n    base_architect:\n      role: \"Core Agent Architecture Designer\"\n      goal: \"Design and implement foundational agent capabilities\"\n      backstory: \"Expert in autonomous systems design with focus on independence\"\n      tools:\n        - SpiderTool\n        - \"anthropic.tools.base\"\n      \n    goal_engineer:\n      role: \"Goal System Designer\"\n      goal: \"Implement goal-setting and tracking framework\"\n      backstory: \"Specialist in objective-oriented system design\"\n      tools:\n        - \"anthropic.tools.goal_tracking\"\n\n  tasks:\n    establish_base:\n      description: \"Create core agent framework with autonomous execution capability\"\n      expected_output: \"Functional base agent with verified independence\"\n      agent: base_architect\n      \n    implement_goals:\n      description: \"Design and implement goal management system\"\n      expected_output: \"Operational goal framework with priority management\"\n      agent: goal_engineer\n\n# Stage 2: Cognition Crew\ncognition_crew:\n  description: \"Implements memory and reasoning systems\"\n  advancement_criteria:\n    - \"Memory systems operational and verified\"\n    - \"Reasoning framework demonstrates chain-of-thought capabilities\"\n    - \"Self-correction mechanisms functional\"\n  \n  agents:\n    memory_architect:\n      role: \"Memory Systems Designer\"\n      goal: \"Implement episodic and working memory systems\"\n      backstory: \"Expert in cognitive architecture design\"\n      tools:\n        - \"anthropic.tools.memory_management\"\n    \n    reasoning_engineer:\n      role: \"Reasoning Systems Designer\"\n      goal: \"Implement logical reasoning and hypothesis testing\"\n      backstory: \"Specialist in AI reasoning systems\"\n      tools:\n        - \"anthropic.tools.reasoning\"\n\n  tasks:\n    implement_memory:\n      description: \"Design and implement memory management systems\"\n      expected_output: \"Functional memory system with context retention\"\n      agent: memory_architect\n      \n    establish_reasoning:\n      description: \"Implement reasoning and self-correction frameworks\"\n      expected_output: \"Operational reasoning system with verification\"\n      agent: reasoning_engineer\n\n# Stage 3: Resource Crew\nresource_crew:\n  description: \"Handles resource management and learning systems\"\n  advancement_criteria:\n    - \"Resource monitoring system operational\"\n    - \"Learning framework demonstrates adaptation\"\n    - \"Performance optimization verified\"\n  \n  agents:\n    resource_manager:\n      role: \"Resource Optimization Specialist\"\n      goal: \"Implement resource monitoring and optimization\"\n      backstory: \"Expert in system resource management\"\n      tools:\n        - \"anthropic.tools.resource_monitoring\"\n    \n    learning_engineer:\n      role: \"Learning Systems Designer\"\n      goal: \"Implement adaptive learning capabilities\"\n      backstory: \"Specialist in machine learning systems\"\n      tools:\n        - \"anthropic.tools.learning\"\n\n  tasks:\n    setup_monitoring:\n      description: \"Implement resource monitoring and optimization\"\n      expected_output: \"Functional resource management system\"\n      agent: resource_manager\n      \n    implement_learning:\n      description: \"Design and implement learning framework\"\n      expected_output: \"Operational learning system with adaptation\"\n      agent: learning_engineer\n\n# Stage 4: Integration Crew\nintegration_crew:\n  description: \"Handles final integration and optimization\"\n  advancement_criteria:\n    - \"Boundary systems operational\"\n    - \"Coordination framework verified\"\n    - \"Optimization systems functional\"\n  \n  agents:\n    integration_architect:\n      role: \"System Integration Specialist\"\n      goal: \"Coordinate final system integration\"\n      backstory: \"Expert in complex system integration\"\n      tools:\n        - \"anthropic.tools.integration\"\n    \n    optimization_engineer:\n      role: \"System Optimization Specialist\"\n      goal: \"Implement final optimization systems\"\n      backstory: \"Specialist in system optimization\"\n      tools:\n        - \"anthropic.tools.optimization\"\n\n  tasks:\n    establish_boundaries:\n      description: \"Implement system boundaries and constraints\"\n      expected_output: \"Verified boundary framework\"\n      agent: integration_architect\n      \n    setup_coordination:\n      description: \"Implement coordination and handoff systems\"\n      expected_output: \"Operational coordination framework\"\n      agent: integration_architect\n      \n    enable_optimization:\n      description: \"Implement self-optimization capabilities\"\n      expected_output: \"Functional optimization system\"\n      agent: optimization_engineer\n</USER_QUERY>\n<ideal_output>\ngraph TD\n    classDef crew fill:#e1f5fe,stroke:#01579b\n    classDef agent fill:#e8f5e9,stroke:#1b5e20\n    classDef task fill:#fff3e0,stroke:#e65100\n    classDef tool fill:#f3e5f5,stroke:#4a148c\n    \nsubgraph \"Stage 1: Foundation Crew\":::crew\n    F[Foundation Crew] --> BA[Base Architect]:::agent\n    F --> GE[Goal Engineer]:::agent\n    BA --> ET[Establish Base]:::task\n    GE --> IG[Implement Goals]:::task\n    ET -.->|uses| ST[SpiderTool]:::tool\n    ET -.->|uses| BT[Base Tools]:::tool\n    IG -.->|uses| GT[Goal Tracking]:::tool\nend\n\nsubgraph \"Stage 2: Cognition Crew\":::crew\n    C[Cognition Crew] --> MA[Memory Architect]:::agent\n    C --> RE[Reasoning Engineer]:::agent\n    MA --> IM[Implement Memory]:::task\n    RE --> ER[Establish Reasoning]:::task\n    IM -.->|uses| MM[Memory Management]:::tool\n    ER -.->|uses| RT[Reasoning Tools]:::tool\nend\n\nsubgraph \"Stage 3: Resource Crew\":::crew\n    R[Resource Crew] --> RM[Resource Manager]:::agent\n    R --> LE[Learning Engineer]:::agent\n    RM --> SM[Setup Monitoring]:::task\n    LE --> IL[Implement Learning]:::task\n    SM -.->|uses| MT[Monitoring Tools]:::tool\n    IL -.->|uses| LT[Learning Tools]:::tool\nend\n\nsubgraph \"Stage 4: Integration Crew\":::crew\n    I[Integration Crew] --> IA[Integration Architect]:::agent\n    I --> OE[Optimization Engineer]:::agent\n    IA --> EB[Establish Boundaries]:::task\n    IA --> SC[Setup Coordination]:::task\n    OE --> EO[Enable Optimization]:::task\n    EB & SC -.->|uses| IT[Integration Tools]:::tool\n    EO -.->|uses| OT[Optimization Tools]:::tool\nend\n\nF -->|Advances to| C\nC -->|Advances to| R\nR -->|Advances to| I\n\nstyle F fill:#e1f5fe,stroke:#01579b\nstyle C fill:#e1f5fe,stroke:#01579b\nstyle R fill:#e1f5fe,stroke:#01579b\nstyle I fill:#e1f5fe,stroke:#01579b\n</ideal_output>\n</example>\n</examples>\n\n"
                },
                {
                    "type": "text",
                    "text": "<user_query>\n{{USER_QUERY}}\n</user_query>"
                }
            ]
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "<diagram_planning>\n1. Main concepts/components:\n- Client-side code\n- Claude (Assistant)\n- Tools\n- Tool choice configurations\n- Chain of thought process\n- Tool use/result flow\n\n2. Relationships:\n- Client provides tools and prompt to Claude\n- Claude processes and decides on tool usage\n- Tool execution happens client-side\n- Results flow back to Claude\n- Claude formulates final response\n\n3. Diagram Type:\n- TD (top-down) to show the sequential flow and decision points\n\n4. Node Structure:\n- Distinct sections for client and Claude\n- Tool choice configuration options\n- Tool execution flow\n- Response handling\n\n5. Relationships/Labels:\n- Show data flow between components\n- Indicate decision points\n- Mark configuration options\n- Display tool use/result cycle\n\n6. Key Considerations:\n- Tool choice configurations (auto/any/tool)\n- Parallel vs sequential tool use\n- Chain of thought inclusion\n- Error handling\n</diagram_planning>\n\n<answer>\n```mermaid\ngraph TD\n    classDef client fill:#e1f3f8,stroke:#333\n    classDef claude fill:#ffe6cc,stroke:#333\n    classDef config fill:#d5e8d4,stroke:#333\n    classDef tool fill:#fff2cc,stroke:#333\n    classDef response fill:#f8cecc,stroke:#333\n\n    %% Client Side\n    C[Client]:::client --> |Provides Tools & Prompt| TC[Tool Configuration]:::config\n    TC --> |Configure| CH[Tool Choice Handler]:::config\n    CH --> |Set| TC1[auto]:::config\n    CH --> |Set| TC2[any]:::config\n    CH --> |Set| TC3[tool]:::config\n    \n    %% Claude Processing\n    TC --> CL[Claude]:::claude\n    CL --> |Analyzes| D{Need Tools?}:::claude\n    \n    %% Decision Flow\n    D -->|Yes| COT[Chain of Thought]:::claude\n    D -->|No| FR[Direct Response]:::response\n    \n    %% Tool Use Flow\n    COT --> TU[Tool Use Request]:::claude\n    TU --> |Extract| TE[Tool Execution]:::tool\n    TE --> |Generate| TR[Tool Result]:::tool\n    \n    %% Result Processing\n    TR --> |Return to| CL\n    CL --> |Formulate| FR\n\n    %% Parallel Tool Use\n    subgraph \"Parallel Tool Configuration\"\n        PT[Parallel Tools]:::config --> |disable_parallel_tool_use=true| ST[Sequential Tools]:::config\n    end\n    \n    %% Tool Result Structure\n    subgraph \"Tool Result Format\"\n        TRF[Tool Result]:::tool\n        TRF --> ID[tool_use_id]:::tool\n        TRF --> CN[content]:::tool\n        TRF --> ER[is_error]:::tool\n    end\n\n    style D fill:#ffe6cc,stroke:#333\n```\n</answer>"
                }
            ]
        }
    ]
)
print(message.content)
